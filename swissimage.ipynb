{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bdb9c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['gid', 'pk_glacier', 'sgi-id', 'name', 'rl_0', 'rl_1', 'rl_2', 'rl_3',\n",
      "       'i_code', 'year_acq', 'year_rel', 'area_km2', 'length_km', 'masl_min',\n",
      "       'masl_med', 'masl_mean', 'masl_max', 'slope_deg', 'aspect_deg',\n",
      "       'geometry'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import box\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import shutil \n",
    "\n",
    "\n",
    "\n",
    "#PATHs\n",
    "glacliers_path = \"glamos/glacier_list.csv\"\n",
    "shape_path_2010 = \"glamos/2010/SGI_2010.shp\"\n",
    "shape_path_2016 = \"glamos/2016/SGI_2016_glaciers.shp\"\n",
    "\n",
    "sgi_2016 = gpd.read_file(shape_path_2016)\n",
    "\n",
    "# Attributes of the shape file\n",
    "print(sgi_2016.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df735360",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(shape_path_2016) \n",
    "if gdf.crs is None: \n",
    "    gdf.set_crs(epsg=2056, inplace=True) # Projection into WGS84 required by GEE \n",
    "gdf_wgs84 = gdf.to_crs(epsg=4326) # Save \n",
    "gdf_wgs84.to_file(\"glamos/SGI_2016_wgs84.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26fd62ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 64 glaciers acquired in 2016. (6.39%)\n"
     ]
    }
   ],
   "source": [
    "# Filter out 2016 glaciers \n",
    "count_before = len(sgi_2016[sgi_2016[\"year_acq\"] <= 2016]) \n",
    "sgi = sgi_2016[sgi_2016[\"year_acq\"] >= 2016] \n",
    "print(f\"Removed {count_before - len(sgi)} glaciers acquired in 2016. ({(count_before - len(sgi)) / count_before * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7b57ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crs after read: EPSG:4326\n",
      "invalid geoms: 0\n",
      "empty geoms: 0\n",
      "geom types: Polygon         1102\n",
      "MultiPolygon     298\n",
      "Name: count, dtype: int64\n",
      "example area m2: count    1.400000e+03\n",
      "mean     6.867138e+05\n",
      "std      3.064828e+06\n",
      "min      1.009541e+04\n",
      "25%      3.275194e+04\n",
      "50%      9.044433e+04\n",
      "75%      3.126283e+05\n",
      "max      7.849365e+07\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# debugging info\n",
    "\n",
    "gdf = gpd.read_file(\"glamos/SGI_2016_wgs84.shp\")\n",
    "print(\"crs after read:\", gdf.crs)\n",
    "\n",
    "gdf_2056 = gdf.to_crs(2056)\n",
    "print(\"invalid geoms:\", (~gdf_2056.is_valid).sum())\n",
    "print(\"empty geoms:\", (gdf_2056.is_empty).sum())\n",
    "print(\"geom types:\", gdf_2056.geom_type.value_counts().head())\n",
    "print(\"example area m2:\", gdf_2056.geometry.area.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4159652f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image id: 20180322T105021_20190705T150938_T20TQP\n"
     ]
    }
   ],
   "source": [
    "# debugging info\n",
    "\n",
    "import ee\n",
    "ee.Initialize(project=\"b3testdrive\")\n",
    "\n",
    "img = (ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
    "       .filterDate(\"2019-07-01\", \"2019-07-10\")\n",
    "       .first()\n",
    "       .select(\"B4\"))\n",
    "\n",
    "print(\"Image id:\", img.id().getInfo())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8504368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download URL created OK (length): 145\n"
     ]
    }
   ],
   "source": [
    "#debugging info\n",
    "\n",
    "import ee\n",
    "ee.Initialize(project=\"b3testdrive\")\n",
    "\n",
    "region = ee.Geometry.Rectangle([7.0, 46.0, 7.01, 46.01])  # tiny region\n",
    "\n",
    "img = (ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
    "       .filterDate(\"2019-07-01\", \"2019-07-10\")\n",
    "       .median()\n",
    "       .select([\"B2\",\"B3\",\"B4\",\"B8\"]))\n",
    "\n",
    "url = img.getDownloadURL({\n",
    "    \"scale\": 10,\n",
    "    \"region\": region,\n",
    "    \"crs\": \"EPSG:4326\",\n",
    "    \"format\": \"GEO_TIFF\"\n",
    "})\n",
    "print(\"Download URL created OK (length):\", len(url))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58a0509c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(gdf) = 1400\n",
      "crs = EPSG:2056\n",
      "total_bounds = [2552348.6644433  1078863.87018848 2827545.1764972  1235126.54123004]\n",
      "example year_acq unique (head) = [2014, 2016, 2016, 2014, 2016]\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "\n",
    "import geemap\n",
    "\n",
    "# Initialisation\n",
    "try:\n",
    "    ee.Initialize(project=\"b3testdrive\")\n",
    "except Exception:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(project=\"b3testdrive\")\n",
    "\n",
    "# --- Configuration Scientifique ---\n",
    "TILE_SIZE_PX = 224\n",
    "RESOLUTION = 10 \n",
    "TILE_SIZE_M = TILE_SIZE_PX * RESOLUTION  # 2240m\n",
    "OUTPUT_DIR = \"dataset/images_raw_2056\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Seuils\n",
    "MIN_INTERSECTION_M2 = 5000\n",
    "MIN_YEAR = 2015 \n",
    "\n",
    "# Charge into EPSG:2056\n",
    "\n",
    "gdf = gpd.read_file(\"glamos/SGI_2016_wgs84.shp\") \n",
    "if gdf.crs.to_epsg() != 2056: \n",
    "    gdf = gdf.to_crs(epsg=2056)\n",
    "\n",
    "\n",
    "def get_sentinel_raw(year):\n",
    "    \"\"\"\n",
    "    Récupère les données brutes (Reflectance).\n",
    "    Pas de .visualize() ! On veut les données scientifiques.\n",
    "    \"\"\"\n",
    "    start = f'{year}-07-01'\n",
    "    end = f'{year}-09-30'\n",
    "    \n",
    "    collection = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\") \\\n",
    "        .filterDate(start, end) \\\n",
    "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20)) \\\n",
    "        .median() # Median to reduce clouds\n",
    "    \n",
    "    # Select bands : Blue, Green, Red, NIR\n",
    "    \n",
    "    return collection.select(['B2', 'B3', 'B4', 'B8'])\n",
    "\n",
    "# Stats\n",
    "stats = { \"tiles_kept\": 0, \"errors\": 0 }\n",
    "\n",
    "print(\"len(gdf) =\", len(gdf))\n",
    "print(\"crs =\", gdf.crs)\n",
    "print(\"total_bounds =\", gdf.total_bounds)  # [minx, miny, maxx, maxy]\n",
    "print(\"example year_acq unique (head) =\", gdf[\"year_acq\"].head().tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a422f37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début du traitement en EPSG:2056...\n",
      "Tiles generated : 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Début du traitement en EPSG:2056...\")\n",
    "\n",
    "for index, row in gdf.iterrows():\n",
    "    g_id = row['pk_glacier']\n",
    "    year = int(row[\"year_acq\"])\n",
    "    \n",
    "    if year < MIN_YEAR: continue \n",
    "\n",
    "    # Geometry (LV95)\n",
    "    geom_shapely = row.geometry\n",
    "    minx, miny, maxx, maxy = geom_shapely.bounds\n",
    "    \n",
    "    # Grid coordinates\n",
    "    x_coords = np.arange(minx, maxx, TILE_SIZE_M)\n",
    "    y_coords = np.arange(miny, maxy, TILE_SIZE_M)\n",
    "    \n",
    "    local_cnt = 0\n",
    "    \n",
    "\n",
    "    \n",
    "    for x in x_coords:\n",
    "        for y in y_coords:\n",
    "            # Tiles\n",
    "            tile_box = box(x, y, x + TILE_SIZE_M, y + TILE_SIZE_M)\n",
    "            \n",
    "            # Filter\n",
    "            if not tile_box.intersects(geom_shapely): continue\n",
    "            if tile_box.intersection(geom_shapely).area < MIN_INTERSECTION_M2: continue\n",
    "            \n",
    "            filename = os.path.join(OUTPUT_DIR, f\"{g_id}_{year}_tile_{local_cnt}.tif\")\n",
    "            if os.path.exists(filename): \n",
    "                local_cnt += 1\n",
    "                continue\n",
    "            \n",
    "            # EPSG:2056 -> EPSG:4326 (required in GEE)\n",
    "            box_gdf = gpd.GeoSeries([tile_box], crs=2056)\n",
    "            box_wgs84 = box_gdf.to_crs(epsg=4326).iloc[0]\n",
    "            \n",
    "            region_ee = ee.Geometry.Rectangle(\n",
    "                [box_wgs84.bounds[0], box_wgs84.bounds[1], box_wgs84.bounds[2], box_wgs84.bounds[3]],\n",
    "                proj='EPSG:4326',\n",
    "                geodesic=False\n",
    "            )\n",
    "            \n",
    "            try:\n",
    "                # Save\n",
    "                geemap.download_ee_image(\n",
    "                    get_sentinel_raw(int(year)),\n",
    "                    filename=filename,\n",
    "                    region=region_ee,   # Area of interest\n",
    "                    scale=10,           # 10m pixels\n",
    "                    crs='EPSG:2056',    # EPSG:2056\n",
    "                    dtype='uint16'      \n",
    "                )\n",
    "                stats[\"tiles_kept\"] += 1\n",
    "                local_cnt += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Erreur {g_id}: {e}\")\n",
    "                stats[\"errors\"] += 1\n",
    "\n",
    "print(f\"Tiles generated : {stats['tiles_kept']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc30c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b7af74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "IMAGE_DIR = \"dataset/images_raw_2056\"\n",
    "MASK_DIR = \"dataset/masks\"\n",
    "SHP_PATH = \"glamos/SGI_2016_wgs84.shp\"\n",
    "\n",
    "os.makedirs(MASK_DIR, exist_ok=True)\n",
    "\n",
    "# Year tolerance\n",
    "YEAR_TOLERANCE = 1 \n",
    "\n",
    "# Classes definitions\n",
    "CLASS_BACKGROUND = 0\n",
    "CLASS_GLACIER = 1\n",
    "CLASS_IGNORE = 255\n",
    "\n",
    "# Project shapefile to EPSG:2056\n",
    "gdf = gpd.read_file(SHP_PATH)\n",
    "gdf = gdf.set_crs(epsg=4326, allow_override=True).to_crs(epsg=2056)\n",
    "if gdf.crs.to_epsg() != 2056:\n",
    "    gdf = gdf.to_crs(epsg=2056)\n",
    "\n",
    "gdf[\"pk_glacier\"] = gdf[\"pk_glacier\"].astype(str)\n",
    "\n",
    "# Spatial index for fast queries\n",
    "sindex = gdf.sindex\n",
    "\n",
    "# List images\n",
    "image_files = [f for f in os.listdir(IMAGE_DIR) if f.endswith('.tif')]\n",
    "total = len(image_files)\n",
    "print(f\"Generate masks for {total} images\")\n",
    "\n",
    "for filename in tqdm(image_files):\n",
    "    \n",
    "    # Parsing du nom : \"UUID_ANNEE_tile_X.tif\"\n",
    "    try:\n",
    "        parts = filename.replace('.tif', '').split('_')\n",
    "        # format : ID_COMPLEX_YEAR_tile_NUMBER\n",
    "\n",
    "        target_year = int(parts[-3]) \n",
    "    \n",
    "        target_id = \"_\".join(parts[:-3])\n",
    "    except Exception as e:\n",
    "        print(f\"   Filename error: {filename} -> {e}\")\n",
    "        continue\n",
    "        \n",
    "    image_path = os.path.join(IMAGE_DIR, filename)\n",
    "    mask_path = os.path.join(MASK_DIR, filename) \n",
    "    \n",
    "    with rasterio.open(image_path) as src:\n",
    "        # Spatial info\n",
    "        out_shape = (src.height, src.width) # Expected (224, 224)\n",
    "        transform = src.transform \n",
    "        bounds = src.bounds \n",
    "        \n",
    "        # Spatial query \n",
    "        bbox_geom = box(bounds.left, bounds.bottom, bounds.right, bounds.top)\n",
    "        \n",
    "        # Filter by spatial index\n",
    "        possible_matches_index = list(sindex.query(bbox_geom))\n",
    "        possible_matches = gdf.iloc[possible_matches_index]\n",
    "        \n",
    "        # Filter by intersection\n",
    "        visible_glaciers = possible_matches[possible_matches.intersects(bbox_geom)].copy()\n",
    "        \n",
    "        # Empty mask\n",
    "        mask = np.zeros(out_shape, dtype=np.uint8)\n",
    "\n",
    "        if not visible_glaciers.empty:\n",
    "            # Check acquisition year\n",
    "            visible_glaciers['year_diff'] = (visible_glaciers['year_acq'] - target_year).abs()\n",
    "            \n",
    "            is_target = visible_glaciers['pk_glacier'].astype(str) == str(target_id)\n",
    "            is_good_year = visible_glaciers['year_diff'] <= YEAR_TOLERANCE\n",
    "            \n",
    "            valid_mask = is_target | is_good_year\n",
    "            \n",
    "            bad_glaciers = visible_glaciers[~valid_mask]  # check neighbors too old/recent\n",
    "            good_glaciers = visible_glaciers[valid_mask]  # target year + recent neighbors\n",
    "            \n",
    "            # Rasterisation\n",
    "            # Fisrt : ignored glaciers (255)\n",
    "        \n",
    "            if not bad_glaciers.empty:\n",
    "                shapes_bad = ((geom, CLASS_IGNORE) for geom in bad_glaciers.geometry)\n",
    "                features.rasterize(\n",
    "                    shapes=shapes_bad,\n",
    "                    out=mask,\n",
    "                    transform=transform,\n",
    "                    default_value=CLASS_IGNORE,\n",
    "                    dtype=np.uint8\n",
    "                )\n",
    "                \n",
    "            # Then: valid glaciers (1)\n",
    "            # If overlap -> keep valid glacier\n",
    "            if not good_glaciers.empty:\n",
    "                shapes_good = ((geom, CLASS_GLACIER) for geom in good_glaciers.geometry)\n",
    "                features.rasterize(\n",
    "                    shapes=shapes_good,\n",
    "                    out=mask,\n",
    "                    transform=transform,\n",
    "                    default_value=CLASS_GLACIER,\n",
    "                    dtype=np.uint8\n",
    "                )\n",
    "        \n",
    "        # Save \n",
    "        # 1 band: uint8, LZW\n",
    "        meta = src.meta.copy()\n",
    "        meta.update({\n",
    "            \"count\": 1,\n",
    "            \"dtype\": 'uint8',\n",
    "            \"driver\": \"GTiff\",\n",
    "            \"compress\": \"lzw\",\n",
    "            \"nodata\": 0 # back = 0\n",
    "        })\n",
    "        \n",
    "        with rasterio.open(mask_path, 'w', **meta) as dst:\n",
    "            dst.write(mask, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e94033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"dataset/images_raw_2056\"\n",
    "MASK_DIR = \"dataset/masks\"\n",
    "\n",
    "# Normalize image (Contrast Stretch)\n",
    "def stretch_image(img_array):\n",
    "    \"\"\"\n",
    "    Take an image (H, W, C) and apply histogram stretch 2%-98%.\n",
    "    \"\"\"\n",
    "    # keep nodata 0\n",
    "    lower = np.percentile(img_array, 2)\n",
    "    upper = np.percentile(img_array, 98)\n",
    "    \n",
    "    # Stretch values between 0 and 1\n",
    "    img_norm = (img_array - lower) / (upper - lower)\n",
    "    img_norm = np.clip(img_norm, 0, 1)\n",
    "    return img_norm\n",
    "\n",
    "# Random choice\n",
    "files = [f for f in os.listdir(MASK_DIR) if f.endswith('.tif')]\n",
    "if not files:\n",
    "    print(\"No files found in mask directory\")\n",
    "else:\n",
    "    sample_file = random.choice(files)\n",
    "    print(f\"Visualisation: {sample_file}\")\n",
    "\n",
    "    img_p = os.path.join(IMAGE_DIR, sample_file)\n",
    "    msk_p = os.path.join(MASK_DIR, sample_file)\n",
    "    print(f\"Image path: {img_p}\")\n",
    "\n",
    "    with rasterio.open(img_p) as src_img, rasterio.open(msk_p) as src_msk:\n",
    "        # GEE : ['B2', 'B3', 'B4', 'B8']\n",
    "        # Indices Python (0-based) : 0=Blue, 1=Green, 2=Red, 3=NIR\n",
    "        \n",
    "        r = src_img.read(3)\n",
    "        g = src_img.read(2)\n",
    "        b = src_img.read(1)\n",
    "        \n",
    "        # Stack RGB\n",
    "        img = np.dstack((r, g, b))\n",
    "        \n",
    "        # Convert in float\n",
    "        img = img.astype(np.float32)\n",
    "        \n",
    "        # Apply function\n",
    "        img_vis = stretch_image(img)\n",
    "        \n",
    "        # Read mask\n",
    "        msk = src_msk.read(1)\n",
    "\n",
    "    # Visualisation\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img_vis)\n",
    "    plt.title(f\"Sentinel-2 (RGB Stretch)\\n{sample_file}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(msk, cmap='gray', interpolation='nearest')\n",
    "    plt.title(\"Mask (Ground Truth)\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e65aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SRC_IMG_DIR = \"dataset/images_raw_2056\"\n",
    "SRC_MASK_DIR = \"dataset/masks\"\n",
    "\n",
    "CLEAN_IMG_DIR = \"dataset/clean/images\"\n",
    "CLEAN_MASK_DIR = \"dataset/clean/masks\"\n",
    "\n",
    "os.makedirs(CLEAN_IMG_DIR, exist_ok=True)\n",
    "os.makedirs(CLEAN_MASK_DIR, exist_ok=True)\n",
    "\n",
    "files = [f for f in os.listdir(SRC_IMG_DIR) if f.endswith('.tif')]\n",
    "corrupted_count = 0\n",
    "valid_count = 0\n",
    "\n",
    "# Clean process\n",
    "\n",
    "for f in tqdm(files):\n",
    "    src_img_path = os.path.join(SRC_IMG_DIR, f)\n",
    "    src_mask_path = os.path.join(SRC_MASK_DIR, f)\n",
    "    \n",
    "    # Check mask existence\n",
    "    if not os.path.exists(src_mask_path):\n",
    "        corrupted_count += 1\n",
    "        continue\n",
    "\n",
    "    is_valid = False\n",
    "    \n",
    "    # Check contents (not empty)\n",
    "    try:\n",
    "        with rasterio.open(src_img_path) as src:\n",
    "            \n",
    "            if src.read().max() > 0:\n",
    "                is_valid = True\n",
    "    except Exception as e:\n",
    "        print(f\"Error {f}: {e}\")\n",
    "    \n",
    "    if is_valid:\n",
    "        shutil.copy2(src_img_path, os.path.join(CLEAN_IMG_DIR, f))\n",
    "        shutil.copy2(src_mask_path, os.path.join(CLEAN_MASK_DIR, f))\n",
    "        valid_count += 1\n",
    "    else:\n",
    "        corrupted_count += 1\n",
    "\n",
    "\n",
    "print(f\"Rejected images : {corrupted_count}\")\n",
    "print(f\"Valid images : {valid_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c2c8c5",
   "metadata": {},
   "source": [
    "# A cause des nuages, on perds 834 images\n",
    "\n",
    "Pour mtn, on peut continuer sans elles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d827e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_IMG_DIR = \"dataset/clean/images\"\n",
    "\n",
    "ORIGINAL_SHP = \"glamos/SGI_2016_wgs84.shp\"\n",
    "\n",
    "OUTPUT_SHP = \"glamos/SGI_2016_VALID_ONLY.shp\"\n",
    "\n",
    "\n",
    "files = [f for f in os.listdir(CLEAN_IMG_DIR) if f.endswith('.tif')]\n",
    "\n",
    "if not files:\n",
    "    raise ValueError(\"Erreur : Le dossier d'images est vide !\")\n",
    "\n",
    "# IDs extraction - expected format : ID_YEAR_tile_X.tif\n",
    "\n",
    "valid_ids = set()\n",
    "for f in tqdm(files):\n",
    "    \n",
    "    parts = f.replace('.tif', '').split('_')\n",
    "    # Rebuild ID\n",
    "    if len(parts) >= 3:\n",
    "        g_id = \"_\".join(parts[:-3])\n",
    "        valid_ids.add(g_id)\n",
    "\n",
    "print(f\" Unique IDs: {len(valid_ids)} \")\n",
    "\n",
    "gdf = gpd.read_file(ORIGINAL_SHP)\n",
    "\n",
    "# Convert ID into string\n",
    "gdf['pk_glacier'] = gdf['pk_glacier'].astype(str)\n",
    "\n",
    "# Filter\n",
    "gdf_valid = gdf[gdf['pk_glacier'].isin(valid_ids)].copy()\n",
    "\n",
    "print(f\" {len(gdf_valid)} polygones kept over {len(gdf)} \")\n",
    "\n",
    "\n",
    "# Save\n",
    "gdf_valid.to_file(OUTPUT_SHP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4cf04b",
   "metadata": {},
   "source": [
    "![alt text](image.png)\n",
    "test zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8907243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DRY_RUN = False  # <--- METTRE A FALSE POUR ACTIVER LE DÉPLACEMENT RÉEL\n",
    "\n",
    "TSV_PATH = \"test_set_idx.tsv\"\n",
    "SRC_IMG_DIR = \"dataset/clean/images\"\n",
    "SRC_MASK_DIR = \"dataset/clean/masks\"\n",
    "DEST_IMG_DIR = \"dataset/test/images\"\n",
    "DEST_MASK_DIR = \"dataset/test/masks\"\n",
    "\n",
    "\n",
    "if not DRY_RUN:\n",
    "    os.makedirs(DEST_IMG_DIR, exist_ok=True)\n",
    "    os.makedirs(DEST_MASK_DIR, exist_ok=True)\n",
    "\n",
    "# Charge target\n",
    "test_set = pd.read_csv(TSV_PATH, sep=\"\\t\")\n",
    "\n",
    "target_ids = set(test_set[\"pk_glacier\"].astype(str).str.strip().str.replace('\"', ''))\n",
    "\n",
    "files = [f for f in os.listdir(SRC_IMG_DIR) if f.endswith('.tif')]\n",
    "\n",
    "files_to_move = []\n",
    "ids_found_in_files = set()\n",
    "\n",
    "# Match\n",
    "for filename in tqdm(files, desc=\"Analyse des fichiers\"):\n",
    "    parts = filename.replace('.tif', '').split('_')\n",
    "    if len(parts) >= 3:\n",
    "        file_glacier_id = \"_\".join(parts[:-3])\n",
    "        \n",
    "        # ID found in target?\n",
    "        if file_glacier_id in target_ids:\n",
    "            files_to_move.append(filename)\n",
    "            ids_found_in_files.add(file_glacier_id)\n",
    "\n",
    "#Compute stats\n",
    "missing_ids = target_ids - ids_found_in_files\n",
    "total_tiles = len(files_to_move)\n",
    "\n",
    "\n",
    "print(f\"Results Dry Run simulation: {DRY_RUN})\")\n",
    "\n",
    "print(f\"Target : {len(target_ids)}\")\n",
    "print(f\"Glaciers found: {len(ids_found_in_files)}\")\n",
    "print(f\"Missing glaciers: {len(missing_ids)}\")\n",
    "print(f\"Total tiles: {total_tiles}\")\n",
    "\n",
    "\n",
    "if len(missing_ids) > 0:\n",
    "    print(f\"Examples of missing IDs: {list(missing_ids)[:5]}\")\n",
    "    print(\"Glaciers found in target but no matching images in clean\")\n",
    "\n",
    "if total_tiles > 0:\n",
    "    if DRY_RUN:\n",
    "        print(f\"\\ntest: {total_tiles} files\")\n",
    "    else:\n",
    "        moved_count = 0\n",
    "        \n",
    "        for filename in tqdm(files_to_move, desc=\"Déplacement\"):\n",
    "            src_img = os.path.join(SRC_IMG_DIR, filename)\n",
    "            src_msk = os.path.join(SRC_MASK_DIR, filename)\n",
    "            \n",
    "            dst_img = os.path.join(DEST_IMG_DIR, filename)\n",
    "            dst_msk = os.path.join(DEST_MASK_DIR, filename)\n",
    "            \n",
    "            try:\n",
    "                shutil.move(src_img, dst_img)\n",
    "                \n",
    "                if os.path.exists(src_msk):\n",
    "                    shutil.move(src_msk, dst_msk)\n",
    "                moved_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error in {filename}: {e}\")\n",
    "                \n",
    "        print(f\"\\n{moved_count} tiles in dataset/test\")\n",
    "else:\n",
    "    print(\"\\nNothing to move\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a1ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ipeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
