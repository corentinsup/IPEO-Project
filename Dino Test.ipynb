{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee757d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "# Hugging Face\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from datasets import load_dataset, Image\n",
    "from transformers.image_utils import load_image\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "#notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "503d4acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3119, 6, 32, 32) NpzFile 'data/glacier_train.npz' with keys: X_train, y_train, means, stds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# load npz\n",
    "train = np.load(\"data/glacier_train.npz\")\n",
    "sh = train[\"X_train\"].shape\n",
    "print(sh, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "531b4ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af720c7c77164444b829a540f0cb1e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7415e08c4a7d486ba1990c666553ac24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"blanchon/INRIA-Aerial-Image-Labeling\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20394dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class TempDataset(Dataset):\n",
    "    def __init__(self, dataset, processor, tile=224, mask_offset=180):\n",
    "        self.dataset = dataset\n",
    "        self.processor = processor\n",
    "        self.mask_offset = mask_offset\n",
    "        self.tile = tile\n",
    "        w, h = dataset[\"image\"][0].size\n",
    "        \n",
    "        \n",
    "        self.cols = int(w // int(tile))\n",
    "        self.rows = int(h // int(tile))\n",
    "        self.tiles_per_image = self.cols * self.rows\n",
    "        self.num_images = len(dataset[\"image\"]) - mask_offset  # paired count\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_images * self.tiles_per_image\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_idx = idx // self.tiles_per_image + self.mask_offset  # image block\n",
    "        patch_idx = idx % self.tiles_per_image\n",
    "        row = patch_idx // self.cols\n",
    "        col = patch_idx % self.cols\n",
    "        box = (\n",
    "            col * self.tile,\n",
    "            row * self.tile,\n",
    "            (col + 1) * self.tile,\n",
    "            (row + 1) * self.tile,\n",
    "        )\n",
    "\n",
    "        image = self.dataset[\"image\"][img_idx].crop(box)\n",
    "        mask = self.dataset[\"image\"][img_idx - self.mask_offset].crop(box) \n",
    "        \n",
    "        image = self.processor(images=image, return_tensors=\"pt\")[\"pixel_values\"].squeeze(0)\n",
    "        mask = np.array(mask)\n",
    "        if mask.ndim == 3:\n",
    "            # If it's a 3D array, take the first channel to make it 2D\n",
    "            mask = mask[:, :, 0]\n",
    "            \n",
    "        mask = torch.tensor(mask // 255).long()\n",
    "        return {\"image\": image, \"mask\": mask}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "187cfa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "# clear torch cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52c1bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10890 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from models.DinoV3.SemanDino import GlacierSegmenter\n",
    "\n",
    "pretrained_model_name = \"facebook/dinov3-vitl16-pretrain-sat493m\"\n",
    "processor = AutoImageProcessor.from_pretrained(pretrained_model_name)\n",
    "\n",
    "model = GlacierSegmenter(2)\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "dataset2 = TempDataset(dataset, processor)\n",
    "\n",
    "# Optimize for faster loading\n",
    "data_loader = DataLoader(dataset2,\n",
    "                         batch_size=8, \n",
    "                         shuffle=True,\n",
    "                         num_workers=2,\n",
    "                         pin_memory=True,\n",
    "                         drop_last=True)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# training loop\n",
    "pb = tqdm(data_loader, total=len(data_loader))\n",
    "for batch in pb:\n",
    "    images = batch[\"image\"]\n",
    "    masks = batch[\"mask\"]\n",
    "        \n",
    "    model.train()\n",
    "    outputs = model(images.to(\"cuda\"))\n",
    "    \n",
    "    loss = F.cross_entropy(outputs, masks.to(\"cuda\"))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    pb.set_description(f\"Loss: {loss.item():.4f}\")    \n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPEO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
