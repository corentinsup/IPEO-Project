{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee757d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "# Hugging Face\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from datasets import load_dataset, Image\n",
    "from transformers.image_utils import load_image\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "#notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "187cfa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "# clear torch cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52c1bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4229:  14%|█▍        | 10/69 [08:09<46:57, 47.76s/it] "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F  # <--- Il manquait cet import\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoImageProcessor\n",
    "\n",
    "# Imports de tes fichiers locaux\n",
    "from models.DinoV3.SemanDino import GlacierSegmenter\n",
    "from models.DinoV3.GlacierDataset import GlacierDataset\n",
    "\n",
    "# --- SETUP ---\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Training on: {device}\")\n",
    "\n",
    "# Modèle\n",
    "model = GlacierSegmenter(num_classes=2)\n",
    "model = model.to(device)\n",
    "\n",
    "# Dataset\n",
    "dataset = GlacierDataset(\n",
    "    image_dir=\"dataset/clean/images/\",\n",
    "    mask_dir=\"dataset/clean/masks/\",\n",
    "    mode=\"train\",\n",
    ")\n",
    "\n",
    "# DataLoader\n",
    "data_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=8, \n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "# Optimizer : On ne lui donne que les paramètres qui demandent un gradient (Le Décodeur)\n",
    "# C'est une bonne pratique quand on freeze une partie du réseau.\n",
    "params_to_update = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.AdamW(params_to_update, lr=1e-4)\n",
    "\n",
    "# --- TRAINING LOOP ---\n",
    "\n",
    "# On met le modèle en mode train UNE FOIS avant la boucle\n",
    "model.train() \n",
    "\n",
    "pb = tqdm(data_loader, total=len(data_loader), desc=\"Training\")\n",
    "\n",
    "for batch in pb:\n",
    "    # CORRECTION 1 : Unpacking du Tuple (pas de dictionnaire)\n",
    "    images, masks = batch\n",
    "    \n",
    "    # Envoi sur GPU\n",
    "    images = images.to(device)\n",
    "    masks = masks.to(device)\n",
    "        \n",
    "    # Forward Pass\n",
    "    outputs = model(images)\n",
    "    \n",
    "    # CORRECTION 2 : Gestion du 255 (Ignore Index)\n",
    "    # On dit à la Loss : \"Si le pixel vaut 255, ne calcule pas d'erreur dessus\"\n",
    "    loss = F.cross_entropy(outputs, masks, ignore_index=255)\n",
    "    \n",
    "    # Backward Pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Affichage\n",
    "    pb.set_description(f\"Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9898cd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recherche des images en cours...\n",
      "Nombre d'images trouvées : 136\n",
      "\n",
      "Image ID: lubis-luftbilder_farbe_000-161-813\n",
      "Date de prise de vue: 2008-08-18 00:00:00+00:00\n",
      "Lien direct 'data' non trouvé, voici les assets disponibles :\n",
      "- lubis-luftbilder_farbe_000-161-813.csv : https://data.geo.admin.ch/ch.swisstopo.lubis-luftbilder_farbe/lubis-luftbilder_farbe_000-161-813/lubis-luftbilder_farbe_000-161-813.csv\n",
      "- lubis-luftbilder_farbe_000-161-813.jpg : https://data.geo.admin.ch/ch.swisstopo.lubis-luftbilder_farbe/lubis-luftbilder_farbe_000-161-813/lubis-luftbilder_farbe_000-161-813.jpg\n",
      "- lubis-luftbilder_farbe_000-161-813_2056.tif : https://data.geo.admin.ch/ch.swisstopo.lubis-luftbilder_farbe/lubis-luftbilder_farbe_000-161-813/lubis-luftbilder_farbe_000-161-813_2056.tif\n",
      "- lubis-luftbilder_farbe-calibration_057.pdf : https://data.geo.admin.ch/ch.swisstopo.lubis-luftbilder_farbe/lubis-luftbilder_farbe_000-161-813/lubis-luftbilder_farbe-calibration_057.pdf\n"
     ]
    }
   ],
   "source": [
    "from pystac_client import Client\n",
    "\n",
    "# 1. URL de l'API STAC\n",
    "STAC_URL = \"https://data.geo.admin.ch/api/stac/v0.9/\"\n",
    "\n",
    "# 2. Initialisation du client\n",
    "client = Client.open(STAC_URL)\n",
    "\n",
    "# --- CORRECTIF CRITIQUE POUR L'ERREUR \"DoesNotConformTo\" ---\n",
    "# On force le client à ignorer la validation stricte du serveur\n",
    "client.add_conforms_to(\"ITEM_SEARCH\")\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# 3. Paramètres de recherche\n",
    "# Bbox: [Ouest, Sud, Est, Nord] -> Ici un rectangle autour de Lausanne\n",
    "bbox_lausanne = [6.61, 46.50, 6.66, 46.54]\n",
    "\n",
    "print(\"Recherche des images en cours...\")\n",
    "\n",
    "# 4. Lancement de la recherche ciblée\n",
    "search = client.search(\n",
    "    collections=[\"ch.swisstopo.lubis-luftbilder_farbe\"], # La collection EXACTE qu'il vous faut\n",
    "    bbox=None,\n",
    "    datetime=\"2008-01-01/2008-12-31\" # Année 2008\n",
    ")\n",
    "\n",
    "# 5. Récupération des résultats\n",
    "items = list(search.items())\n",
    "print(f\"Nombre d'images trouvées : {len(items)}\")\n",
    "\n",
    "# 6. Affichage des liens de téléchargement\n",
    "if items:\n",
    "    # On prend la première image pour l'exemple\n",
    "    item = items[0]\n",
    "    print(f\"\\nImage ID: {item.id}\")\n",
    "    print(f\"Date de prise de vue: {item.datetime}\")\n",
    "    \n",
    "    # Recherche du fichier GeoTIFF complet (souvent sous la clé 'data' ou finissant par .tif)\n",
    "    image_asset = item.assets.get(\"data\")\n",
    "    \n",
    "    if image_asset:\n",
    "        print(f\"Lien de téléchargement (TIF) : {image_asset.href}\")\n",
    "        print(\"-> Vous pouvez télécharger ce lien pour votre CNN.\")\n",
    "    else:\n",
    "        # Si la clé 'data' n'existe pas, on liste tout pour trouver le .tif\n",
    "        print(\"Lien direct 'data' non trouvé, voici les assets disponibles :\")\n",
    "        for key, asset in item.assets.items():\n",
    "            print(f\"- {key} : {asset.href}\")\n",
    "else:\n",
    "    print(\"Aucune image trouvée pour cette zone et cette date.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPEO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
